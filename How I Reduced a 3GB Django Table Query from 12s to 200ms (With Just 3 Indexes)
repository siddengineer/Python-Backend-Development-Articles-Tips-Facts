ðŸ”Ž Why Queries Get Slow

When a table grows (like 3 GB+), queries can drag if:

Youâ€™re filtering (WHERE) on non-indexed columns â†’ database scans the entire table.

Youâ€™re joining on columns without indexes.

Youâ€™re ordering (ORDER BY) without a matching index.

Youâ€™re querying composite conditions (e.g., WHERE status='active' AND created_at > ...) without a composite index.

âš¡ What Fixed It (Adding 3 Indexes)

Hereâ€™s how adding the right indexes cut the query time:

1. Filter Column Index

If you often query:

SELECT * FROM orders WHERE status = 'shipped';


Indexing status (a B-Tree index) makes lookups instant instead of scanning millions of rows.

class Order(models.Model):
    status = models.CharField(max_length=20, db_index=True)

2. Date/Time Index (Range Queries)

For queries like:

SELECT * FROM orders WHERE created_at >= '2025-01-01';


A B-Tree index on created_at speeds up filtering by date ranges.

class Order(models.Model):
    created_at = models.DateTimeField(db_index=True)

3. Composite Index (Multiple Columns Together)

If you query:

SELECT * FROM orders 
WHERE status = 'shipped' AND created_at >= '2025-01-01'
ORDER BY created_at DESC;


A composite index (status, created_at) means the database can filter + sort in one go.

class Meta:
    indexes = [
        models.Index(fields=["status", "created_at"]),
    ]

ðŸ“‰ Results

Before indexes â†’ full table scan (reading all 3 GB, ~12s).

After indexes â†’ direct B-Tree lookups (~200ms).

ðŸ›  Pro Tips

Always run EXPLAIN ANALYZE <query> in PostgreSQL/MySQL to see if itâ€™s doing a Seq Scan (bad) or Index Scan (good).

Donâ€™t just add indexes randomly â†’ they take disk space and slow down writes.

Add indexes based on your actual queries (from logs or django-debug-toolbar).

Django migrations will create the indexes automatically once defined in models.
